<!-- ---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

<style>
.publication {
    font-family: "Microsoft YaHei",
    line-height: 1.4;
    margin-bottom: 20px;
}
.pub-title {
    font-weight: 700;           
    font-size: 18px;           
    margin: 0 0 8px 0;         
    color: #000;
}
.pub-authors {
    font-family: "Microsoft YaHei",
    margin: 3px 0;
    font-size: 15px;
    font-weight: normal;       
    color: rgba(0,0,0,0.9);    
}
.pub-venue-links {
    margin: 2px 0;
    font-style: italic;
}
.pub-venue {
    display: inline-block;
    margin-right: 5px;
    font-weight: bold;
}
.pub-links {
    display: inline-block;
}
.pub-links a {
    color: #0645AD;
    text-decoration: none;
}
.pub-links a::before {         

}
.pub-links a::after {          

}
.pub-links a + a {             
    margin-left: 5px;
}
h2 {
    font-family: "Microsoft YaHei", 
    margin-top: 20px;
    margin-bottom: 15px;
}
hr {
    margin: 10px 0;
    height: 1px;
    background-color: #ddd;
    border: none;
}
.section-title {
    font-family: "Microsoft YaHei", sans-serif;
    font-weight: 900;
    font-size: 32px;
    margin-bottom: 20px;
    color: #2850a7;  // Ê∑±ÈÇÉÁöÑËìùËâ≤
    letter-spacing: 0.5px;
}
</style>

<div class="section-title">Conference Papers</div>
<hr>

<h1 class="category" style="color: #2850a7;">Efficient Reasoning</h1>

<div class="publication">
  <div class="pub-title">CyclicReflex: Improving Large Reasoning Models via Cyclical Reflection Token Scheduling</div>
  <div class="pub-authors"><span style="font-weight: bold; text-decoration: underline; color:blue;">Chongyu Fan</span>, Yihua Zhang, Jinghan Jia, Alfred Hero, Sijia Liu</div>
  <div class="pub-venue-links">
    <span class="pub-links">[<a href="https://arxiv.org/abs/2506.11077">Paper</a>] [<a href="https://github.com/OPTML-Group/CyclicReflex">Code</a>]</span>
  </div>
</div>

<div class="publication">
  <div class="pub-title">EPiC: Towards Lossless Speedup for Reasoning Training through Edge-Preserving CoT Condensation</div>
  <div class="pub-authors">Jinghan Jia, Hadi Reisizadeh, <span style="font-weight: bold; text-decoration: underline; color:blue;">Chongyu Fan</span>, Nathalie Baracaldo, Mingyi Hong, Sijia Liu</div>
  <div class="pub-venue-links">
    <span class="pub-links">[<a href="https://arxiv.org/abs/2506.04205">Paper</a>] [<a href="https://github.com/OPTML-Group/EPiC">Code</a>]</span>
  </div>
</div>

<h1 class="category" style="color: #2850a7;">Machine Unlearning</h1>

<div class="publication">
  <div class="pub-title">Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond</div>
  <div class="pub-authors"><span style="font-weight: bold; text-decoration: underline; color:blue;">Chongyu Fan*</span>, Jinghan Jia*, Yihua Zhang, Anil Ramakrishna, Mingyi Hong, Sijia Liu</div>
  <div class="pub-venue-links">
    <span class="pub-venue">ICML 2025</span>
    <span class="pub-links">[<a href="https://arxiv.org/abs/2502.05374">Paper</a>] [<a href="https://github.com/OPTML-Group/Unlearn-Smooth">Code</a>]</span>
  </div>
</div>

<div class="publication">
  <div class="pub-title">Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning</div>
  <div class="pub-authors"><span style="font-weight: bold; text-decoration: underline; color:blue;">Chongyu Fan*</span>, Jiancheng Liu*, Licong Lin*, Jinghan Jia, Ruiqi Zhang, Song Mei, Sijia Liu</div>
  <div class="pub-venue-links">
    <span class="pub-links">[<a href="https://arxiv.org/pdf/2410.07163">Paper</a>] [<a href="https://github.com/OPTML-Group/Unlearn-Simple">Code</a>]</span>
  </div>
</div>

<div class="publication">
  <div class="pub-title">UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models</div>
  <div class="pub-authors">Yihua Zhang, <span style="font-weight: bold; text-decoration: underline; color:blue;">Chongyu Fan</span>, Yimeng Zhang, Yuguang Yao, Jinghan Jia, Jiancheng Liu, Gaoyuan Zhang, Gaowen Liu, Ramana Rao Kompella, Xiaoming Liu, Sijia Liu</div>
  <div class="pub-venue-links">
    <span class="pub-venue">NeurIPS 2024</span>
    <span class="pub-links">[<a href="https://arxiv.org/abs/2402.11846">Paper</a>] [<a href="https://github.com/OPTML-Group/UnlearnCanvas">Code</a>] [<a href="https://unlearn-canvas.netlify.app/">Website</a>]</span>
  </div>
</div>

<div class="publication">
  <div class="pub-title">Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models</div>
  <div class="pub-authors">Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, <span style="font-weight: bold; text-decoration: underline; color:blue;">Chongyu Fan</span>, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu</div>
  <div class="pub-venue-links">
    <span class="pub-venue">NeurIPS 2024</span>
    <span class="pub-links">[<a href="https://arxiv.org/abs/2405.15234">Paper</a>] [<a href="https://github.com/OPTML-Group/AdvUnlearn">Code</a>]</span>
  </div>
</div>

<div class="publication">
  <div class="pub-title">Challenging Forgets: Unveiling the Worst-case Forget Sets in Machine Unlearning</div>
  <div class="pub-authors"><span style="font-weight: bold; text-decoration: underline; color:blue;">Chongyu Fan*</span>, Jiancheng Liu*, Alfred Hero, Sijia Liu</div>
  <div class="pub-venue-links">
    <span class="pub-venue">ECCV 2024</span>
    <span class="pub-links">[<a href="https://arxiv.org/abs/2403.07362">Paper</a>] [<a href="https://github.com/OPTML-Group/Unlearn-WorstCase">Code</a>]</span>
  </div>
</div>

<div class="publication">
  <div class="pub-title">SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation</div>
  <div class="pub-authors"><span style="font-weight: bold; text-decoration: underline; color:blue;">Chongyu Fan*</span>, Jiancheng Liu*, Yihua Zhang, Dennis Wei, Eric Wong, Sijia Liu</div>
  <div class="pub-venue-links">
    <span class="pub-venue">ICLR 2024 <span style="color:red">Spotlight</span></span>
    <span class="pub-links">[<a href="https://arxiv.org/abs/2310.12508">Paper</a>] [<a href="https://github.com/OPTML-Group/Unlearn-Saliency">Code</a>] [<a href="https://www.optml-group.com/posts/salun_iclr24">Website</a>]</span>
  </div>
</div>

<div style="height: 150px;"></div> -->


---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<style>
/* ============  Publications Container  ============ */
.publications-container{
  background:#fff;
  border-radius:12px;
  padding:22px 25px;
  box-shadow:0 3px 15px rgba(0,0,0,.06);
  border:1px solid rgba(0,0,0,.05);
  margin-top:30px; /* ‰∏é‰∏ä‰∏ÄÊùøÂùóÁïôÁ©∫Èöô */
}

.publications-container h2{
  color:#333;
  margin:22px 0 15px 0;
  font-size:1.3rem;
  padding-bottom:8px;
  border-bottom:2px solid #f0f0f0;
}
.publications-container h2:first-child{margin-top:0}

/* ============  Á±ªÂà´ÂàóË°®  ============ */
.publication-category ul{
  list-style-type:disc;
  padding-left:25px;
  margin-bottom:15px;
}
.publication-category li{
  margin-bottom:10px;
  padding-left:5px;
  line-height:1.4;
}

/* ============  ËÆ∫ÊñáË°åÂÜÖÊ†∑Âºè  ============ */
.pub-title{font-weight:700;font-size:18px;color:#000}
.pub-authors{margin:3px 0;font-size:15px;color:rgba(0,0,0,.9)}
.pub-venue{font-style:italic;font-weight:bold}
.pub-links a{
  color:#0645AD;
  text-decoration:none;
  transition:color .2s;
}
.pub-links a:hover{
  color:#8244B8;
  text-decoration:underline;
}

/* Áªü‰∏ÄÁöÑ section headingÔºåÂèØ‰∏éÂÖ∂‰ªñÈ°µÈù¢Â§çÁî® */
.section-title {
    font-family: "Microsoft YaHei", sans-serif;
    font-weight: 900;
    font-size: 32px;
    margin-bottom: 20px;
    color: #2850a7;  // Ê∑±ÈÇÉÁöÑËìùËâ≤
    letter-spacing: 0.5px;
}
</style>

<div class="section-title">Conference Papers</div>

<div class="publications-container">

  <!-- =========  Efficient Reasoning  ========= -->
  <h2>‚ö° Efficient Reasoning</h2>
  <div class="publication-category">
    <ul>
      <li>
        <span class="pub-title">CyclicReflex: Improving Large Reasoning Models via Cyclical Reflection Token Scheduling</span><br/>
        <span class="pub-authors"><strong><u style="color:blue;">Chongyu Fan</u></strong>, Yihua Zhang, Jinghan Jia, Alfred Hero, Sijia Liu</span><br/>
        <span class="pub-links">[<a href="https://arxiv.org/abs/2506.11077">Paper</a>] [<a href="https://github.com/OPTML-Group/CyclicReflex">Code</a>]</span>
      </li>

      <li>
        <span class="pub-title">EPiC: Towards Lossless Speedup for Reasoning Training through Edge-Preserving CoT Condensation</span><br/>
        <span class="pub-authors">Jinghan Jia, Hadi Reisizadeh, <strong><u style="color:blue;">Chongyu Fan</u></strong>, Nathalie Baracaldo, Mingyi Hong, Sijia Liu</span><br/>
        <span class="pub-links">[<a href="https://arxiv.org/abs/2506.04205">Paper</a>] [<a href="https://github.com/OPTML-Group/EPiC">Code</a>]</span>
      </li>
    </ul>
  </div>

  <!-- =========  Machine Unlearning  ========= -->
  <h2>üßπ Machine Unlearning</h2>
  <div class="publication-category">
    <ul>
      <li>
        <span class="pub-title">Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond</span><br/>
        <span class="pub-authors"><strong><u style="color:blue;">Chongyu Fan*</u></strong>, Jinghan Jia*, Yihua Zhang, Anil Ramakrishna, Mingyi Hong, Sijia Liu</span><br/>
        <span class="pub-venue">ICML 2025</span>
        <span class="pub-links">[<a href="https://arxiv.org/abs/2502.05374">Paper</a>] [<a href="https://github.com/OPTML-Group/Unlearn-Smooth">Code</a>]</span>
      </li>

      <li>
        <span class="pub-title">Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning</span><br/>
        <span class="pub-authors"><strong><u style="color:blue;">Chongyu Fan*</u></strong>, Jiancheng Liu*, Licong Lin*, Jinghan Jia, Ruiqi Zhang, Song Mei, Sijia Liu</span><br/>
        <span class="pub-links">[<a href="https://arxiv.org/pdf/2410.07163">Paper</a>] [<a href="https://github.com/OPTML-Group/Unlearn-Simple">Code</a>]</span>
      </li>

      <li>
        <span class="pub-title">UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models</span><br/>
        <span class="pub-authors">Yihua Zhang, <strong><u style="color:blue;">Chongyu Fan</u></strong>, Yimeng Zhang, Yuguang Yao, Jinghan Jia, Jiancheng Liu, Gaoyuan Zhang, Gaowen Liu, Ramana Rao Kompella, Xiaoming Liu, Sijia Liu</span><br/>
        <span class="pub-venue">NeurIPS 2024</span>
        <span class="pub-links">[<a href="https://arxiv.org/abs/2402.11846">Paper</a>] [<a href="https://github.com/OPTML-Group/UnlearnCanvas">Code</a>] [<a href="https://unlearn-canvas.netlify.app/">Website</a>]</span>
      </li>

      <li>
        <span class="pub-title">Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models</span><br/>
        <span class="pub-authors">Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, <strong><u style="color:blue;">Chongyu Fan</u></strong>, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu</span><br/>
        <span class="pub-venue">NeurIPS 2024</span>
        <span class="pub-links">[<a href="https://arxiv.org/abs/2405.15234">Paper</a>] [<a href="https://github.com/OPTML-Group/AdvUnlearn">Code</a>]</span>
      </li>

      <li>
        <span class="pub-title">Challenging Forgets: Unveiling the Worst-case Forget Sets in Machine Unlearning</span><br/>
        <span class="pub-authors"><strong><u style="color:blue;">Chongyu Fan*</u></strong>, Jiancheng Liu*, Alfred Hero, Sijia Liu</span><br/>
        <span class="pub-venue">ECCV 2024</span>
        <span class="pub-links">[<a href="https://arxiv.org/abs/2403.07362">Paper</a>] [<a href="https://github.com/OPTML-Group/Unlearn-WorstCase">Code</a>]</span>
      </li>

      <li>
        <span class="pub-title">SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation</span><br/>
        <span class="pub-authors"><strong><u style="color:blue;">Chongyu Fan*</u></strong>, Jiancheng Liu*, Yihua Zhang, Dennis Wei, Eric Wong, Sijia Liu</span><br/>
        <span class="pub-venue">ICLR 2024 <span style="color:red;">Spotlight</span></span>
        <span class="pub-links">[<a href="https://arxiv.org/abs/2310.12508">Paper</a>] [<a href="https://github.com/OPTML-Group/Unlearn-Saliency">Code</a>] [<a href="https://www.optml-group.com/posts/salun_iclr24">Website</a>]</span>
      </li>
    </ul>
  </div>

</div>
